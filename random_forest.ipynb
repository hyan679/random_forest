{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree\n",
    "## I try to use decisiontree to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "#load data\n",
    "with h5py.File('./data/train/images_training.h5', 'r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "with h5py.File('./data/train/labels_training.h5', 'r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "with h5py.File('./data/test/images_testing.h5', 'r') as H:\n",
    "    data_test = np.copy(H['datatest'])\n",
    "with h5py.File('./data/test/labels_testing_2000.h5', 'r') as H:\n",
    "    label_test = np.copy(H['labeltest'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "#private variable depth is not necessary\n",
    "#I hope use this variable can make the code run faster\n",
    "#decision tree do not need to be binary tree, but it is the easist tree data structure, I suppose\n",
    "class node:\n",
    "    value = None\n",
    "    left_child = None\n",
    "    right_child = None\n",
    "    depth = 0\n",
    "\n",
    "    def __init__(self, value=None, depth=None):\n",
    "        self.value = value\n",
    "        self.depth = depth\n",
    "\n",
    "#I find that multi-classifier is much more difficult than the ordinary one.\n",
    "#So I choose to build 10 decision tree\n",
    "#each tree only focus on figuring out probability that each data belongs to specific label\n",
    "class DecisionTree:\n",
    "    num_tree = 10\n",
    "    root = [node(depth=0) for i in range(num_tree)]\n",
    "    threshold = 0.2\n",
    "    acce_resu = 0.8\n",
    "    min_info_gain = 0.01\n",
    "    max_depth = 16\n",
    "    data_train = np.array([])\n",
    "    label_train = np.array([])\n",
    "    scale = 1.2\n",
    "    \n",
    "    def __init__(self, num_tree=10, threshold=0.2, acce_resu=0.8, min_info_gain=0.01, max_depth=16):\n",
    "        num_tree = num_tree\n",
    "        root = [node(depth=0) for i in range(num_tree)]\n",
    "        threshold = threshold\n",
    "        acce_resu = acce_resu\n",
    "        min_info_gain = min_info_gain\n",
    "        max_depth = max_depth\n",
    "\n",
    "    def buildtree(self, point, row, column, label_num):\n",
    "        max_info_gain = 0\n",
    "        temp = [0, 0, [[], []], -1]\n",
    "        row_len = len(row)\n",
    "        new_col = copy.deepcopy(column)\n",
    "        mini_set_num = 0.1*row_len\n",
    "        #scan each pixel in order to find out whether the pixel can effectively divide the data\n",
    "        for i in column:\n",
    "            #count the numbers in order to calculate the information gain\n",
    "            count = [0, 0]\n",
    "            new_row = [[], []]\n",
    "            for j in row:\n",
    "                if self.data_train[j, i] > self.threshold:\n",
    "                    new_row[1].append(j)\n",
    "                    if label_train[j] == label_num:\n",
    "                        count[1] = count[1]+1\n",
    "                else:\n",
    "                    new_row[0].append(j)\n",
    "                    if label_train[j] == label_num:\n",
    "                        count[0] = count[0]+1\n",
    "            new_row0_len = len(new_row[0])\n",
    "            new_row1_len = len(new_row[1])\n",
    "            #if the whole data set cannot be divided into two parts, \n",
    "            #the classification is useless \n",
    "            if new_row1_len < mini_set_num or new_row0_len < mini_set_num:\n",
    "                new_col.remove(i)\n",
    "                continue\n",
    "            else:\n",
    "                p1 = count[0]/new_row0_len\n",
    "                p3 = count[1]/new_row1_len\n",
    "                #If the data is divided perfectly\n",
    "                if p1 > self.acce_resu and p3 > self.acce_resu:\n",
    "                    point.value = i\n",
    "                    point.left_child = node(value=float(p1), depth=point.depth+1)\n",
    "                    point.right_child = node(value=float(p3), depth=point.depth+1)\n",
    "                    print('best')\n",
    "                    return\n",
    "                #If one part of the data is divied perfectly\n",
    "                elif count[0] == 0 or p1 > self.acce_resu:\n",
    "                    point.value = i\n",
    "                    point.left_child = node(value=float(p1), depth=point.depth+1)\n",
    "                    if point.depth == self.max_depth:\n",
    "                        point.right_child = node(value=float(p3), depth=point.depth+1)\n",
    "                    else:\n",
    "                        point.right_child = node(depth=point.depth+1)\n",
    "                        new_col.remove(i)\n",
    "                        self.buildtree(point.right_child, new_row[1], new_col, label_num)\n",
    "                    return\n",
    "                #If another part of the data is divieds perfectly\n",
    "                elif count[1] == 0 or p3 > self.acce_resu:\n",
    "                    point.value = i\n",
    "                    point.right_child = node(value=float(p3), depth=point.depth+1)\n",
    "                    if point.depth == self.max_depth:\n",
    "                        point.left_child = node(value=float(p1), depth=point.depth+1)\n",
    "                    else:\n",
    "                        point.left_child = node(depth=point.depth+1)\n",
    "                        new_col.remove(i)\n",
    "                        self.buildtree(point.left_child, new_row[0], new_col, label_num)\n",
    "                    return\n",
    "                else:\n",
    "                    #if do not have the perfect attribute\n",
    "                    #then calculate the information gain\n",
    "                    #find the maximum and record some feature\n",
    "                    p2 = 1-p1\n",
    "                    p4 = 1-p3\n",
    "                    old_p1 = (count[0]+count[1])/row_len\n",
    "                    old_p2 = 1-old_p1\n",
    "                    info_gain = new_row0_len/row_len*(p1*math.log(p1)+p2*math.log(p2))+new_row1_len/row_len*(p3*math.log(p3)+p4*math.log(p4))-old_p1*math.log(old_p1)-old_p2*math.log(old_p2)\n",
    "                    if info_gain > max_info_gain:\n",
    "                        max_info_gain = info_gain\n",
    "                        temp = [p1, p3, new_row, i]\n",
    "        \n",
    "        point.value = temp[3]\n",
    "        if point.depth == self.max_depth:\n",
    "                    point.left_child = node(value=float(temp[0]), depth=point.depth+1)\n",
    "                    point.right_child = node(value=float(temp[1]), depth=point.depth+1)\n",
    "                    return\n",
    "\n",
    "        if max_info_gain > self.min_info_gain:\n",
    "            point.left_child = node(depth=point.depth+1)\n",
    "            point.right_child = node(depth=point.depth+1)\n",
    "            new_col.remove(temp[3])\n",
    "            self.buildtree(point.left_child, temp[2][0], new_col, label_num)\n",
    "            self.buildtree(point.right_child, temp[2][1], new_col, label_num)\n",
    "        else:\n",
    "            point.left_child = node(value=float(temp[0]), depth=point.depth+1)\n",
    "            point.right_child = node(value=float(temp[1]),depth=point.depth+1)\n",
    "\n",
    "    #there are 10 decision tree which need to build\n",
    "    #use the whole data to build each tree takes too much time, I suppose\n",
    "    #so randomly divide the data into 10 groups\n",
    "    #and then build each trees\n",
    "    def fit(self, data_train, label_train):\n",
    "        self.data_train =data_train\n",
    "        self.label_train = label_train\n",
    "        len_row0 = self.data_train.shape[0]\n",
    "        column0 = list(range(self.data_train.shape[1]))\n",
    "        temp = int(len_row0/self.num_tree*self.scale)\n",
    "        for i in range(self.num_tree):\n",
    "            print('start to build '+str(i)+' decisiontree')\n",
    "            self.buildtree(self.root[i], np.random.randint(low=0, high=len_row0, size=temp), column0, i)\n",
    "    \n",
    "    #the value of each node should be either the index of pixel(int) or the result probability(float) for the leaf nodes\n",
    "    #as mentioned above, I build 10 decision tree and each decision tree only focus on the probability of one piece of data belonging to specific label\n",
    "    #so in the 'predict' function, each piece of data must be input into the whole 10 decision trees and see which decision tree get the maximum probability\n",
    "    #this piece of data is prediected to the label(the same as the index of the decision tree)\n",
    "    def predict(self, data_test):\n",
    "        prediction = []\n",
    "        for i in data_test:\n",
    "            max_poss = 0\n",
    "            pos_label = -1\n",
    "            for index, point in enumerate(self.root):\n",
    "                while 1:\n",
    "                    temp = isinstance(point.value, float)\n",
    "                    if temp:\n",
    "                        if max_poss < point.value:\n",
    "                            max_poss = point.value\n",
    "                            pos_label = index\n",
    "                        elif max_poss == point.value and max_poss != 0 :\n",
    "                            print('can not classify well')\n",
    "                        break\n",
    "                    elif isinstance(point.value, int):\n",
    "                        if i[point.value] > self.threshold:\n",
    "                            point = point.right_child\n",
    "                            continue\n",
    "                        else:\n",
    "                            point = point.left_child\n",
    "                            continue\n",
    "            prediction.append(pos_label)\n",
    "        return np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to build 0 decisiontree\n",
      "start to build 1 decisiontree\n",
      "start to build 2 decisiontree\n",
      "start to build 3 decisiontree\n",
      "start to build 4 decisiontree\n",
      "start to build 5 decisiontree\n",
      "start to build 6 decisiontree\n",
      "start to build 7 decisiontree\n",
      "start to build 8 decisiontree\n",
      "start to build 9 decisiontree\n",
      "can not classify well\n",
      "0.7055\n",
      "166.67553305625916\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "deci_tree = DecisionTree()\n",
    "deci_tree.fit(data_train, label_train)\n",
    "output = deci_tree.predict(data_test[:2000])\n",
    "count = 0\n",
    "for i in range(2000):\n",
    "    if output[i] == label_test[i]:\n",
    "        count = count+1\n",
    "print(count/2000)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
