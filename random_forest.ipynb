{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Random Forest Algorithm\n",
    "### Tag: Fashion MNIST, Random Forest without Scikit-learn, Image Recognition, multi-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/ec2-user/.local/lib/python3.9/site-packages (23.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in /home/ec2-user/.local/lib/python3.9/site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/.local/lib/python3.9/site-packages (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U h5py numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "with h5py.File('./data/train/images_training.h5', 'r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "with h5py.File('./data/train/labels_training.h5', 'r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "with h5py.File('./data/test/images_testing.h5', 'r') as H:\n",
    "    data_test = np.copy(H['datatest'])\n",
    "with h5py.File('./data/test/labels_testing_2000.h5', 'r') as H:\n",
    "    label_test = np.copy(H['labeltest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Keep Top 2000 Rows of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, depth=0, value=None):\n",
    "        self.depth = depth  # not necessary but can simplify bulid code\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.value = value\n",
    "        # If the data type of value is float -> it is a leaf node, the value is the probability\n",
    "        # If the data type of value is int  -> it is a branch node, the value is the column name     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "# Binary tree\n",
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cls = 0,\n",
    "        max_depth = 12,\n",
    "        min_pct = 0.05,\n",
    "        threshold = 0.32,\n",
    "        worst_gini = 0.95\n",
    "    ):\n",
    "        self.root = node(depth=0)\n",
    "        self.cls = cls\n",
    "        self.max_depth = max_depth\n",
    "        self.min_pct = min_pct\n",
    "        self.threshold = threshold\n",
    "        self.worst_gini = worst_gini\n",
    "        self.data = None\n",
    "        self.label = None\n",
    "\n",
    "\n",
    "    def build(self, point, column, row):\n",
    "        gini_list = [{'gini':1},]\n",
    "        row_len = len(row)\n",
    "        min_set_num = round(self.min_pct * row_len) + 1 # Ensure > 0\n",
    "        # Scan each pixel in order to find out whether the pixel can effectively divide the data\n",
    "        for i in column:\n",
    "            condition = self.data[row,i] < self.threshold\n",
    "            condition_true = sum(condition)\n",
    "            condition_false = row_len - condition_true\n",
    "            # If the data set cannot be divided into two parts,\n",
    "            # The condition is useless\n",
    "            if condition_true > min_set_num and condition_false > min_set_num:\n",
    "                t_t = sum(condition & (self.label[row]==self.cls))\n",
    "                f_t = sum(~condition & (self.label[row]==self.cls))\n",
    "                p_tt = t_t / condition_true\n",
    "                p_ft = f_t / condition_false\n",
    "                gini = (1 - p_tt**2 - ((condition_true - t_t) / condition_true)**2)*(condition_true / row_len)\\\n",
    "                    + (1 - p_ft**2 - ((condition_false - f_t) / condition_false)**2)*(condition_false / row_len)\n",
    "                gini_list.append({'gini':gini, 'column':i, 'condition':condition})\n",
    "        best_res = min(gini_list, key=lambda x:x.get('gini'))\n",
    "        if best_res.get('gini') < self.worst_gini and point.depth < self.max_depth:\n",
    "            best_column = int(best_res.get('column'))\n",
    "            point.value = best_column\n",
    "            point.left_child = node(depth=point.depth + 1)\n",
    "            point.right_child = node(depth=point.depth + 1)\n",
    "            \n",
    "            condition = best_res.get('condition')\n",
    "            new_col = deepcopy(column)\n",
    "            new_col.remove(best_column)\n",
    "            self.build(point.left_child, new_col, row[condition])\n",
    "            self.build(point.right_child, new_col, row[~condition])\n",
    "        else:\n",
    "            point.value = float(sum(self.label[row]==self.cls)/row_len)\n",
    "            \n",
    "            \n",
    "    def fit(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.build(self.root, list(range(data.shape[1])), np.arange(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Random Forest(N v 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N v 1: Each specific tree is only responsible for judging whether the data belongs to a specific classification\n",
    "class RandomForest:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth = 12,\n",
    "        min_pct = 0.05,\n",
    "        threshold = 0.3,\n",
    "        worst_gini = 0.95\n",
    "    ):\n",
    "        self.root_list = [\n",
    "            DecisionTree(\n",
    "                cls = i,\n",
    "                max_depth = max_depth,\n",
    "                min_pct = min_pct,\n",
    "                threshold = threshold,\n",
    "                worst_gini = worst_gini\n",
    "            )       for i in range(10)\n",
    "        ]\n",
    "\n",
    "\n",
    "    def fit(self, data_train, label_train):\n",
    "        for tree_index, decision_tree in enumerate(self.root_list):\n",
    "            print(\"start to build\", tree_index, \"decision tree\")\n",
    "            decision_tree.fit(data_train, label_train)\n",
    "\n",
    "    def predict(self, data_test):\n",
    "        predict = []\n",
    "        for i in data_test:\n",
    "            pro_list = []\n",
    "            for dt in self.root_list:\n",
    "                point = dt.root\n",
    "                while 1:\n",
    "                    if isinstance(point.value, float):\n",
    "                        pro_list.append({'class':dt.cls, 'probability':point.value})\n",
    "                        break\n",
    "                    elif isinstance(point.value, int):\n",
    "                        if i[point.value] < dt.threshold:\n",
    "                            point = point.left_child\n",
    "                        else:\n",
    "                            point = point.right_child\n",
    "                    else:\n",
    "                        print('error:', str(type(point.value)))\n",
    "            predict.append(max(pro_list,key=lambda x:x['probability'])['class'])\n",
    "        return np.array(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to build 0 decision tree\n",
      "start to build 1 decision tree\n",
      "start to build 2 decision tree\n",
      "start to build 3 decision tree\n",
      "start to build 4 decision tree\n",
      "start to build 5 decision tree\n",
      "start to build 6 decision tree\n",
      "start to build 7 decision tree\n",
      "start to build 8 decision tree\n",
      "start to build 9 decision tree\n",
      "Accuracy:  0.755\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest()\n",
    "rf.fit(data_train, label_train)\n",
    "predict = rf.predict(data_test[:2000])\n",
    "print('Accuracy: ', sum(predict == label_test)/2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
